{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be7c0cbc-8528-44cd-bbf3-926b19211d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b9679-1168-40c9-819b-2f521a420cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.environ.get(\"HUGGING_FACE_TOKEN\")\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdaac13-88a9-472c-b25d-dd792e4b8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data  = datasets.load_dataset(\"israel/JOPUjJHxWmI5x\", use_auth_token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e8bba-8f2e-4782-add8-bfb67c51b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt4(instruction, input_text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\\n{input_text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a06369-5fe7-4090-b4d1-28967d4edb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, data_sources, output_dir='model_evaluation', sleep_duration=2, resume=False):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    start_index = 0\n",
    "    data_source_name = \"-\".join(data_sources)\n",
    "    output_filename = os.path.join(output_dir, f\"gpt4_responses-{data_source_name}.csv\")\n",
    "    print(f\"gpt4_responses-{data_source_name}.csv\")\n",
    "    \n",
    "    if resume and os.path.exists(output_filename):\n",
    "        with open(output_filename, mode='r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            data = list(reader)\n",
    "        start_index = len(data)-1\n",
    "        print(f\"Resuming from Test Case {start_index}\")\n",
    "    else:\n",
    "        with open(output_filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['instruction', 'input', 'ouptput','datasource', 'response'])  # Column headers\n",
    "\n",
    "    datasource_data = test_data.filter(lambda example: example['datasource'] in data_sources)\n",
    "    resume_data = datasource_data[start_index:]\n",
    "\n",
    "    with open(output_filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        for i, (\n",
    "            instruction,\n",
    "            input_text,\n",
    "            output_text,\n",
    "            data_source\n",
    "        ) in enumerate(\n",
    "            tqdm(\n",
    "                zip(\n",
    "                    resume_data['instruction'],\n",
    "                    resume_data['input'],\n",
    "                    resume_data['output'],\n",
    "                    resume_data['datasource']\n",
    "                ),\n",
    "                total=len(datasource_data['input']),\n",
    "                initial=start_index\n",
    "            )\n",
    "        ): \n",
    "            try:\n",
    "                response = query_gpt4(instruction, input_text)\n",
    "                writer.writerow([instruction, input_text, output_text, data_source, response])\n",
    "            except Exception as e:\n",
    "                print(f\"API Error for {data_source} - Test Case {start_index + i}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "            time.sleep(sleep_duration)  # Add a sleep to avoid API rate limits\n",
    "    \n",
    "    print(f\"Final save: Saved responses to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201e764-2197-41a3-be29-ad7247de2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_test = Dataset.from_dict(evaluation_data['test'][:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8f82a-2ab7-4725-a323-eab522dbf0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data['test'].unique('datasource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65293cae-0748-4933-999e-cfb936d805bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(evaluation_data['test'], ['afrisent','masakhanews'], resume=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b7e9d-46df-4d15-8e91-7df6e79843f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.read_csv('model_evaluation/gpt4_responses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ce19d-a9e7-4116-b9b9-c139cd4a31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11399f3e-0e87-4c6e-8d7c-af91a43e9735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
