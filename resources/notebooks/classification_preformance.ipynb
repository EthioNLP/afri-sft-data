{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "import demoji\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8089 entries, 0 to 8088\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Instruction  8089 non-null   object\n",
      " 1   Input Text   8089 non-null   object\n",
      " 2   Datasource   8089 non-null   object\n",
      " 3   response     7319 non-null   object\n",
      " 4   gold_label   8089 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 316.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Replace the current path value with the correct path to the GPT-4 dataset directory.\n",
    "PATH = \"/home/lewi/Documents/project/Gpt-4\"\n",
    "data = pd.read_csv(os.path.join(PATH,  'all_amh_LLaMA_eval_responses - all_amh_LLaMA_eval_responses.csv'))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clean the response \n",
    "\n",
    "simmilar_characters = {\"ሐ\":\"ሀ\",\"ሑ\":\"ሁ\",\"ሒ\":\"ሂ\",\"ሓ\":\"ሃ\",\"ሔ\":\"ሄ\",\"ሕ\":\"ህ\",\"ሖ\":\"ሆ\",\\\n",
    "                       \"ኀ\":\"ሀ\",\"ኁ\":\"ሁ\",\"ኂ\":\"ሂ\",\"ኃ\":\"ሃ\",\"ኄ\":\"ሄ\",\"ኅ\":\"ህ\",\"ኆ\":\"ሆ\",\\\n",
    "                       \"ሠ\":\"ሰ\",\"ሡ\":\"ሱ\",\"ሢ\":\"ሲ\",\"ሣ\":\"ሳ\",\"ሤ\":\"ሴ\",\"ሥ\":\"ስ\",\"ሦ\":\"ሶ\",\"ሧ\":\"ሷ\",\\\n",
    "                       \"ዐ\":\"አ\",\"ዑ\":\"ኡ\",\"ዒ\":\"ኢ\",\"ዓ\":\"ኣ\",\"ዔ\":\"ኤ\",\"ዕ\":\"እ\",\"ዖ\":\"ኦ\",\\\n",
    "                       \"ጸ\":\"ፀ\",\"ጹ\":\"ፁ\",\"ጺ\":\"ፂ\",\"ጻ\":\"ፃ\",\"ጼ\":\"ፄ\",\"ጽ\":\"ፅ\",\"ጾ\":\"ፆ\"}\n",
    " \n",
    "def clean_am(tweet):\n",
    "    \n",
    "    #remove all the english alphabet and numbers\n",
    "    #tweet = re.sub('[a-zA-Z0-9]', '', tweet)\n",
    "    tweet = re.sub('[+/..]', ' ', tweet)\n",
    "    #remove muliple spacing\n",
    "    tweet = re.sub('\\s\\s+', '', tweet)\n",
    "    #remove all the symbols\n",
    "    tweet = re.sub('[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}፡»~፣።፤-•{…}«፡፡→←]', '', tweet)\n",
    "\n",
    "    #replace same amharic alphabet\n",
    "    for letter, althernative in simmilar_characters.items():\n",
    "           # print(letter, althernative)\n",
    "            tweet = tweet.replace(letter, althernative)\n",
    "\n",
    "    return tweet\n",
    "    \n",
    "def simmilar_char(text):\n",
    "    \n",
    "    for letter, althernative in simmilar_characters.items():\n",
    "        text = text.replace(letter, althernative)\n",
    "\n",
    "    return text \n",
    "\n",
    "def clean_am_response(df, col_name):\n",
    "    \n",
    "    dataframe = df.copy()\n",
    "    col_name = str(col_name)\n",
    "    dataframe[col_name] = dataframe[col_name].fillna('NA').astype(str)\n",
    "    dataframe[col_name] = dataframe[col_name].apply(lambda x: demoji.replace(x,' '))\n",
    "    dataframe[col_name] = dataframe[col_name].apply(lambda tweet:' '.join([word for word in tweet.split() if len(word)>1]))\n",
    "    dataframe[col_name] = dataframe[col_name].apply(lambda tweet: tweet.strip())\n",
    "    dataframe[col_name] = dataframe[col_name].apply(lambda tweet: clean_am(tweet)) \n",
    "    dataframe[col_name] = dataframe[col_name].apply(lambda tweet: simmilar_char(tweet)) \n",
    "    \n",
    "    return dataframe[col_name]\n",
    "\n",
    "\n",
    "\n",
    "def clean_response(df, col_name):\n",
    "    count = []\n",
    "\n",
    "    words = [\"አዎንታዊ\", \"አሉታዊ\", \"ገለልተኛ\"]\n",
    "    for text in df[col_name]:\n",
    "        for word in words:\n",
    "            if word in text:\n",
    "                count.append(word)\n",
    "                break\n",
    "        else:\n",
    "            \n",
    "            count.append(\"nothing_predicted\")\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_similarity(str1, str2):\n",
    "    return difflib.SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "def isin_metrics(str1,str2):\n",
    "    return str1 in str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49111/1248796285.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gold_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'string_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "for index, row in data.iterrows():\n",
    "    similarity = string_similarity(row['gold_label'], row['response'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25806451612903225"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = data.gold_label.unique().tolist()\n",
    "unique_classes += [\"nothing_predicted\"]\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {class_name:index for index,class_name in enumerate(unique_classes)}\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    y_true.append(classes[row['ouptput']])\n",
    "    output = [isin_metrics(str1,row['response']) for str1 in classes.keys()]\n",
    "    \n",
    "    if True in output:\n",
    "        y_pred.append(output.index(True))\n",
    "    else:\n",
    "        # TODO : how should we handle in the case where we dont find any of the classes\n",
    "        y_pred.append(classes['nothing_predicted'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dataset = data[:1999].copy()\n",
    "answer = pd.DataFrame()\n",
    "col_name = ['response','gold_label']\n",
    "for i in col_name:\n",
    "    \n",
    "    clean_dataset[i] = clean_am_response(data, i)\n",
    "    \n",
    "# clean_dataset = clean_am_response(data, col_name)\n",
    "for i in col_name:\n",
    "    \n",
    "    answer[i] = clean_response(clean_dataset, i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "nothing_predicted       0.00      0.00      0.00         0\n",
      "             አሉታዊ       0.79      0.21      0.33      1337\n",
      "            አዎንታዊ       0.26      0.49      0.34       438\n",
      "            ገለልተኛ       0.12      0.08      0.10       224\n",
      "\n",
      "         accuracy                           0.25      1999\n",
      "        macro avg       0.29      0.19      0.19      1999\n",
      "     weighted avg       0.60      0.25      0.30      1999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lewi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lewi/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evalu = (classification_report(clean_dataset['gold_label'], answer['response'], zero_division='warn'))\n",
    "print(evalu)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
